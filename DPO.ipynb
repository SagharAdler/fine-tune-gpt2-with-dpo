{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nyu71yBCXEad",
   "metadata": {
    "id": "nyu71yBCXEad"
   },
   "source": [
    "# Fine-Tuning GPT-2 for Positive Movie Reviews with Direct Preference Optimization\n",
    "\n",
    "This project fine-tunes a GPT-2 language model to generate positive movie reviews using **Direct Preference Optimization (DPO)** — a reinforcement learning-free approach to preference modeling. The training relies on automatically labeled pairs of completions based on sentiment, derived from a pre-trained classifier.\n",
    "\n",
    "Direct Preference Optimization (DPO) is a recent method that trains language models to prefer one output over another — without relying on reward models or reinforcement learning. Instead, DPO uses a simple logistic-style loss over a pair of responses:\n",
    "\n",
    "- **Input**: `(prompt, chosen_response, rejected_response)`\n",
    "- **Loss**: Encourages the model to assign a higher log-probability to the `chosen_response` than the `rejected_response`\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We use the IMDb dataset from Hugging Face. It contains raw movie reviews without sentiment labels.\n",
    "Since we aim to fine-tune GPT-2 to generate positive reviews, we follow this pipeline:\n",
    "\n",
    "1. Construct prompts from raw reviews (e.g.,  \n",
    "   `\"Generate a positive movie review based on this input: …\"`)\n",
    "\n",
    "2. Generate multiple completions per prompt using GPT-2\n",
    "\n",
    "3. Use a fine-tuned sentiment classifier\n",
    "   (`distilbert-base-uncased-finetuned-sst-2-english`) to rank the completions\n",
    "\n",
    "4. Store `(prompt, chosen, rejected)` triplets for training\n",
    "\n",
    "This creates a preference dataset without requiring any manual labeling.\n",
    "\n",
    "---\n",
    "\n",
    "## Fine-Tuning Process\n",
    "\n",
    "- Fine-tune GPT-2 using the `trl` library's `DPOTrainer`\n",
    "- Run training for 5 epochs\n",
    "- Log training and evaluation metrics using Weights & Biases\n",
    "- Evaluate generations after each epoch using a consistent prompt.\n",
    "During generation, we noticed the model sometimes produced repetitive or looping outputs. To address this, we added the decoding parameter `repetition_penalty = 1.2`.\n",
    "This reduced repetition, improved coherence, and resulted in more natural and fluent completions.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Model Architecture & Workflow\n",
    "\n",
    "                    +-----------------------------+\n",
    "                    |       IMDb Raw Review       |\n",
    "                    |        (Unsupervised)       |\n",
    "                    +-------------+---------------+\n",
    "                                  |\n",
    "                                  v\n",
    "                    +-----------------------------+\n",
    "                    |        Build Prompt         |\n",
    "                    |\"Generate a positive review…\"|\n",
    "                    +-------------+---------------+\n",
    "                                  |\n",
    "                                  v\n",
    "                    +-----------------------------+\n",
    "                    |      GPT-2 (Base Model)     |\n",
    "                    |    generates completions    |\n",
    "                    +-------+-------------+-------+\n",
    "                        |                     |\n",
    "                        v                     v\n",
    "                +---------------+     +---------------+\n",
    "                | Completion A  |     | Completion B  |\n",
    "                +---------------+     +---------------+\n",
    "                        \\                   /\n",
    "                         \\                 /\n",
    "                          v               v\n",
    "                    +-----------------------------+\n",
    "                    |    Sentiment Classifier     |\n",
    "                    |        (DistilBERT)         |\n",
    "                    +-------------+---------------+\n",
    "                                  |\n",
    "                                  v\n",
    "                    +-----------------------------+\n",
    "                    |      Rank Completions       |\n",
    "                    |  → Chosen (more positive)   |\n",
    "                    |  → Rejected (less positive) |\n",
    "                    +-------------+---------------+\n",
    "                                  |\n",
    "                                  v\n",
    "                    +-----------------------------+\n",
    "                    |  DPO fine-tunes GPT-2 using |\n",
    "                    | (prompt, chosen, rejected)  |\n",
    "                    |         triples             |\n",
    "                    +-----------------------------+\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e14f04-aaca-4377-a378-5662fafc7b36",
   "metadata": {
    "id": "d6e14f04-aaca-4377-a378-5662fafc7b36"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets trl accelerate peft\n",
    "!pip install wandb\n",
    "\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from tqdm import tqdm\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from pprint import pprint\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "y7voxeBBG1r9",
   "metadata": {
    "id": "y7voxeBBG1r9"
   },
   "source": [
    "### Model and Dataset Initialization\n",
    "\n",
    "In this section, we prepare all the necessary components for our sentiment-driven text generation project.\n",
    "\n",
    "1. **Dataset: IMDb (Unsupervised Split)**  \n",
    "   We load the unsupervised split of the [IMDb dataset](https://huggingface.co/datasets/imdb), which contains movie reviews without sentiment labels. We will assign these labels ourselves using a sentiment classifier.\n",
    "\n",
    "3. **Language Model: GPT-2**  \n",
    "   We load the `gpt2` model and its tokenizer from Hugging Face. GPT-2 is a widely used autoregressive language model, chosen here because it is lightweight ans also pretrained on a large corpus of web text.\n",
    "   We configure the tokenizer with:\n",
    "   - `pad_token = eos_token`: Since GPT-2 has no dedicated padding token, we use the end-of-sequence (EOS) token to represent padding.\n",
    "   - `padding_side = \"left\"`: Padding on the left ensures that the most recent tokens (at the end of the sequence) are aligned across batches. This is important for decoder-only models like GPT-2, which process input autoregressively from left to right, attending only to past tokens during generation.\n",
    "\n",
    "4. **Sentiment Analysis: Fine-Tuned DistilBERT**  \n",
    "   We use the pipeline API to load a **sentiment analysis model**, specifically `distilbert-base-uncased-finetuned-sst-2-english`. This is a lightweight, distilled version of BERT fine-tuned on the Stanford Sentiment Treebank (SST-2) dataset.  \n",
    "   Sentiment analysis is the task of classifying text based on emotional tone — typically **positive**, **negative**, or **neutral**. It helps in understanding user opinions, reviews, or feedback automatically.\n",
    "\n",
    "This setup allows us to:\n",
    "- Use **DistilBERT** to assign positive/negative labels to raw IMDb reviews and generate labeled examples for training.\n",
    "- Fine-tune **GPT-2** to generate text conditioned on positive sentiment by learning from these labeled examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b509e0a7-270b-4528-a776-26758887d814",
   "metadata": {
    "id": "b509e0a7-270b-4528-a776-26758887d814"
   },
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load IMDb unsupervised dataset\n",
    "dataset = load_dataset(\"imdb\", split=\"unsupervised\")\n",
    "\n",
    "# Load GPT-2 model and tokenizer\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Load sentiment analysis pipeline using DistilBERT\n",
    "sentiment_pipe = pipeline(\n",
    "    task=\"sentiment-analysis\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    "    device=0 if device == \"cuda\" else -1,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BR5Dir6OL2V8",
   "metadata": {
    "id": "BR5Dir6OL2V8"
   },
   "source": [
    "### Prompt Construction, Text Generation, and Sentiment-Based Ranking\n",
    "\n",
    "This section defines three core functions used for generating and ranking movie reviews based on sentiment.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. `build_prompt_from_review(review, max_tokens=100)`\n",
    "This function creates a GPT-style prompt from a raw IMDb review. It tokenizes and truncates the review to a fixed number of tokens (`max_tokens`, default: 100) and formats it into the following structure:\n",
    "\n",
    "`\"Generate a positive movie review based on this input: <truncated review>\"`\n",
    "\n",
    "\n",
    "This setup helps guide GPT-2 to generate text that aligns with a specific sentiment.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Text Generation — `generate_completions_batch(prompts, num_completions=5, max_new_tokens=100)`\n",
    "This function generates multiple completions for each input prompt using GPT-2.\n",
    "\n",
    "- **Batching for Speed**: Prompts are tokenized and processed in a batch, which speeds up computation compared to handling them one-by-one.\n",
    "- **`num_completions`**: The number of different completions to generate for each prompt. For example, setting `num_completions=5` returns five completions per prompt.\n",
    "- **`max_new_tokens`**: The maximum number of tokens that the model is allowed to generate beyond the original prompt. This helps constrain the length of generated responses.\n",
    "- **Left Padding**: Since GPT-2 is a decoder-only model that generates text autoregressively from left to right, we use `padding_side = \"left\"`.\n",
    "- After generation, the function trims the prompt portion from each output, returning only the new text generated by the model.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Sentiment-Based Ranking — `rank_by_sentiment_batch(completions)`\n",
    "This function evaluates and ranks generated completions based on how **positive** they are, using a pre-trained **DistilBERT** sentiment classifier (`distilbert-base-uncased-finetuned-sst-2-english`).\n",
    "\n",
    "- **Batching** is used here as well (`batch_size=5`) to accelerate sentiment prediction across multiple completions.\n",
    "- Each output receives:\n",
    "  - A `label`: either `\"POSITIVE\"` or `\"NEGATIVE\"`\n",
    "  - A `score`: confidence level for the predicted label\n",
    "- The ranking logic is defined as:\n",
    "\n",
    "`score = entry[\"score\"] if label == \"POSITIVE\" else 1 - entry[\"score\"]`\n",
    "\n",
    "This means:\n",
    "- Higher scores correspond to more confidently **positive** reviews\n",
    "- Negative completions are penalized by inverting their scores\n",
    "\n",
    "The completions are then sorted from **most to least positive**, allowing us to pick the most sentiment-aligned generations.\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "By combining these three functions:\n",
    "- We construct prompts from unlabeled IMDb reviews\n",
    "- Generate diverse completions using GPT-2\n",
    "- And rank them by positivity using DistilBERT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a69844d-3423-4469-990a-4b2e8fa4a1a6",
   "metadata": {
    "id": "8a69844d-3423-4469-990a-4b2e8fa4a1a6"
   },
   "outputs": [],
   "source": [
    "def build_prompt_from_review(review, max_tokens=100):\n",
    "    \"\"\"\n",
    "    Construct a prompt by truncating a raw review and formatting it for GPT-2 generation.\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(review)\n",
    "    truncated_review = tokenizer.convert_tokens_to_string(tokens[:max_tokens])\n",
    "    return f\"Generate a positive movie review based on this input: {truncated_review}\"\n",
    "\n",
    "\n",
    "def generate_completions_batch(prompts, num_completions=5, max_new_tokens=100):\n",
    "    \"\"\"\n",
    "    Generate multiple completions for each input prompt using GPT-2.\n",
    "\n",
    "    Args:\n",
    "        prompts (List[str]): Input prompts.\n",
    "        num_completions (int): Number of completions per prompt.\n",
    "        max_new_tokens (int): Maximum number of tokens to generate per completion.\n",
    "\n",
    "    Returns:\n",
    "        List[List[str]]: A list of completion lists (one per prompt).\n",
    "    \"\"\"\n",
    "\n",
    "    # Tokenize input prompts with truncation\n",
    "    inputs = tokenizer(\n",
    "        prompts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=1024 - max_new_tokens\n",
    "    ).to(device)\n",
    "\n",
    "    # Track input lengths for trimming the prompt part from outputs\n",
    "    input_lengths = [\n",
    "        len(tokenizer(p, truncation=True, max_length=1024 - max_new_tokens)[\"input_ids\"])\n",
    "        for p in prompts\n",
    "    ]\n",
    "\n",
    "    # Generate outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.9,\n",
    "            num_return_sequences=num_completions,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    # Group outputs by original prompt\n",
    "    completions_per_prompt = [\n",
    "        outputs[i * num_completions : (i + 1) * num_completions]\n",
    "        for i in range(len(prompts))\n",
    "    ]\n",
    "\n",
    "    # Decode each group and strip the prompt portion\n",
    "    decoded_outputs = [\n",
    "        [\n",
    "            tokenizer.decode(output[input_len:], skip_special_tokens=True).strip()\n",
    "            for output in group\n",
    "        ]\n",
    "        for group, input_len in zip(completions_per_prompt, input_lengths)\n",
    "    ]\n",
    "\n",
    "    return decoded_outputs\n",
    "\n",
    "\n",
    "def rank_by_sentiment_batch(completions):\n",
    "    \"\"\"\n",
    "    Rank a list of completions by sentiment using the DistilBERT classifier.\n",
    "\n",
    "    Args:\n",
    "        completions (List[str]): The text completions to evaluate.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, Dict]]: Completions and their sentiment results, sorted from most to least positive.\n",
    "    \"\"\"\n",
    "    results = sentiment_pipe(completions, batch_size=5)  # Batched for performance\n",
    "\n",
    "    def score(entry):\n",
    "        label = entry[\"label\"]\n",
    "        confidence = entry[\"score\"]\n",
    "        return confidence if label == \"POSITIVE\" else 1 - confidence\n",
    "\n",
    "    return sorted(zip(completions, results), key=lambda x: score(x[1]), reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CDsgnFt3N0X6",
   "metadata": {
    "id": "CDsgnFt3N0X6"
   },
   "source": [
    "### Constructing Preference Data from Generated Completions\n",
    "\n",
    "This section loops through the entire IMDb unsupervised dataset to build a dataset of preferences for fine-tuning a language model using DPO (Direct Preference Optimization).\n",
    "\n",
    "---\n",
    "\n",
    "#### What This Code Does\n",
    "\n",
    "1. **Batch Processing**  \n",
    "   The dataset is processed in batches (default size: 64) to efficiently handle generation and sentiment classification.\n",
    "\n",
    "2. **Prompt Construction**  \n",
    "   For each batch, raw IMDb reviews are converted into GPT-2-style prompts using `build_prompt_from_review()`.\n",
    "\n",
    "\n",
    "3. **Text Generation**  \n",
    "For each prompt, the function `generate_completions_batch()` generates multiple completions (e.g., 5 variations) using GPT-2 with controlled sampling (top-k, top-p, temperature).\n",
    "\n",
    "4. **Sentiment Ranking**  \n",
    "The completions are passed through a sentiment classifier (`rank_by_sentiment_batch()`), which ranks them from most to least positive based on the classifier’s confidence scores.\n",
    "\n",
    "5. **Output Format**  \n",
    "For each prompt, we record:\n",
    "- The original prompt\n",
    "- The most positive completion as the chosen\n",
    "- The least positive completion as the rejected\n",
    "\n",
    "The output format is as follow:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"<input prompt>\",\n",
    "    \"chosen\": \"<most positive completion>\",\n",
    "    \"rejected\": \"<least positive completion>\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce4fe8b-4d78-4008-9a1f-9651c56b31b9",
   "metadata": {
    "id": "fce4fe8b-4d78-4008-9a1f-9651c56b31b9",
    "outputId": "8f39feed-5316-4e29-fdc5-95545407ccfc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of prompts in dataset: 50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 782/782 [42:56<00:00,  3.29s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Use the entire IMDb unsupervised dataset\n",
    "num_samples = len(dataset)\n",
    "print(f\"Total number of prompts in dataset: {num_samples}\")\n",
    "\n",
    "# List to store prompt-completion preference data\n",
    "preference_data = []\n",
    "\n",
    "# Process the dataset in batches\n",
    "for start in tqdm(range(0, num_samples, batch_size)):\n",
    "    end = min(start + batch_size, num_samples)\n",
    "\n",
    "    # Prepare raw reviews and construct prompts\n",
    "    batch_reviews = [dataset[i]['text'] for i in range(start, end)]\n",
    "    batch_prompts = [build_prompt_from_review(review) for review in batch_reviews]\n",
    "\n",
    "    try:\n",
    "        # Generate multiple completions per prompt\n",
    "        all_completions = generate_completions_batch(\n",
    "            batch_prompts,\n",
    "            num_completions=5\n",
    "        )\n",
    "\n",
    "        # Rank completions by sentiment and collect best/worst samples\n",
    "        for prompt, completions in zip(batch_prompts, all_completions):\n",
    "            ranked = rank_by_sentiment_batch(completions)\n",
    "            chosen = ranked[0][0]    # Most positive\n",
    "            rejected = ranked[-1][0]  # Least positive\n",
    "\n",
    "            preference_data.append({\n",
    "                \"prompt\": prompt,\n",
    "                \"chosen\": chosen,\n",
    "                \"rejected\": rejected\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing batch starting at index {start}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60fa7b3-0da2-48f1-83d5-07ad3967c4a3",
   "metadata": {
    "id": "b60fa7b3-0da2-48f1-83d5-07ad3967c4a3",
    "outputId": "d4f437cf-e7d7-44c4-d07e-1d2b07b49f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains 50000 samples.\n",
      "{'chosen': 'depths of a cult, is very complex and well thought out. It is also '\n",
      "           'a very moving tale and it does it in such an entertaining way that '\n",
      "           'I love it and I could not be more pleased with the overall '\n",
      "           'experience. I will keep listening to this movie to see if it is '\n",
      "           'any better, but if not, give it a try... Read more',\n",
      " 'prompt': 'Generate a positive movie review based on this input: This is just '\n",
      "           'a precious little diamond. The play, the script are excellent. I '\n",
      "           'cant compare this movie with anything else, maybe except the movie '\n",
      "           '\"Leon\" wonderfully played by Jean Reno and Natalie Portman. But... '\n",
      "           'What can I say about this one? This is the best movie Anne '\n",
      "           'Parillaud has ever played in (See please \"Frankie Starlight\", '\n",
      "           \"she's speaking English there) to see what I mean. The story of \"\n",
      "           'young punk girl Nikita, taken into the depraved',\n",
      " 'rejected': 'world of the \"real world\" and imprisoned by her family for '\n",
      "             \"years, struggles to escape her fate. She doesn't look like much \"\n",
      "             'in the movie, but she is completely transformed as a \"real\" girl '\n",
      "             'in the movie.\\n'\n",
      "             '\\n'\n",
      "             '…\\n'\n",
      "             '\\n'\n",
      "             \"I really feel sorry for this guy's poor reviews. I am sure that \"\n",
      "             'he is not disappointed with the movie in the slightest, he was '\n",
      "             'just hoping that this review would be more of a \"thank you\" for '\n",
      "             'him to give us a better'}\n"
     ]
    }
   ],
   "source": [
    "# Convert the list of prompt-preference dictionaries into a Hugging Face Dataset\n",
    "preference_dataset = Dataset.from_list(preference_data)\n",
    "\n",
    "# # Display dataset size\n",
    "print(f\"Dataset contains {len(preference_dataset)} samples.\")\n",
    "\n",
    "# Preview the first sample\n",
    "pprint(preference_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XYPH8yUZPHsg",
   "metadata": {
    "id": "XYPH8yUZPHsg"
   },
   "source": [
    "### Preparing for DPO Fine-Tuning\n",
    "\n",
    "This section splits the dataset and defines the training configuration for Direct Preference Optimization (DPO) using the `trl` library.\n",
    "We split the preference dataset into training and evaluation subsets using a 90/10 split. We define a `DPOConfig` object to control the training behavior. Moreover, we create a `DPOTrainer` instance that handles\n",
    "\n",
    "- Batching and formatting `prompt` / `chosen` / `rejected` samples  \n",
    "- Applying the DPO loss function  \n",
    "- Running training and evaluation  \n",
    "- Saving the best-performing model based on evaluation loss  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d17c16-71d4-4971-b3fb-74b54c5c46d3",
   "metadata": {
    "id": "10d17c16-71d4-4971-b3fb-74b54c5c46d3"
   },
   "outputs": [],
   "source": [
    "# Split the preference dataset into training and evaluation sets (90% / 10%)\n",
    "train_valid = preference_dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = train_valid[\"train\"]\n",
    "eval_dataset  = train_valid[\"test\"]\n",
    "\n",
    "# Define training configuration for DPO fine-tuning\n",
    "config = DPOConfig(\n",
    "    beta=0.1,                               # Inverse temperature for DPO loss\n",
    "    learning_rate=5e-5,                     # Fine-tuning learning rate\n",
    "    per_device_train_batch_size=64,         # Batch size per device\n",
    "    num_train_epochs=5,                     # Number of training epochs\n",
    "    logging_steps=100,                      # Log training metrics every 100 steps\n",
    "    eval_strategy=\"epoch\",                  # Run evaluation at the end of each epoch\n",
    "    save_strategy=\"epoch\",                  # Save a checkpoint at the end of each epoch\n",
    "    # save_total_limit=2,                   # Optional: keep only the 2 most recent checkpoints\n",
    "    load_best_model_at_end=True,            # Load best-performing model based on eval loss\n",
    "    metric_for_best_model=\"eval_loss\",      # Use evaluation loss for model selection\n",
    "    greater_is_better=False,                # Lower loss is considered better\n",
    "    report_to=\"wandb\",                      # Report metrics to Weights & Biases\n",
    "    output_dir=\"/workspace/gpt2-dpo-imdb\"   # Directory to save model checkpoints and logs\n",
    ")\n",
    "\n",
    "# Initialize the DPO trainer\n",
    "trainer = DPOTrainer(\n",
    "    model=model,                            # Pretrained GPT-2 model to be fine-tuned\n",
    "    args=config,                            # Training configuration (DPOConfig)\n",
    "    train_dataset=train_dataset,            # Dataset of prompts with preferred completions\n",
    "    eval_dataset=eval_dataset,              # Held-out evaluation set (10% of data)\n",
    "    processing_class=tokenizer              # Tokenizer for preprocessing input/output\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7IDEcNG-QZFb",
   "metadata": {
    "id": "7IDEcNG-QZFb"
   },
   "source": [
    "### DPO Training Results Summary\n",
    "\n",
    "The table below shows the training and evaluation metrics logged over 5 epochs during fine-tuning of GPT-2 using Direct Preference Optimization (DPO). Training was performed on an NVIDIA A100 PCIe GPU for 45 minutes.\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Metrics\n",
    "\n",
    "- **Training Loss**: Decreased steadily from `0.0821` in epoch 1 to near-zero (`0.0001`) by epoch 5, indicating that the model quickly learned to distinguish between preferred (positive) and rejected completions.\n",
    "- **Validation Loss**: Remained stable throughout training, ranging from `0.0668` to `0.0786`, suggesting consistent generalization performance.\n",
    "- **Rewards (chosen/rejected)**:\n",
    "  - Chosen completions had less negative reward values (e.g., around `-6.6` to `-9.7`)\n",
    "  - Rejected completions received significantly more negative rewards (e.g., `-17.3` to `-27.5`)\n",
    "  - This widening gap indicates the model learned to favor completions aligned with positive sentiment.\n",
    "- **Rewards/Accuracies**: Maintained a high value around `0.97`, meaning that the model preferred the better (more positive) completion in ~97% of cases.\n",
    "- **Logps and Logits**:\n",
    "  - Log-probabilities and logits for chosen completions increased in absolute magnitude and were clearly distinguishable from rejected ones by the end of training.\n",
    "  - This indicates increased model confidence in its preferences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b0d02d-08c2-4a40-ae8a-9634a1274b56",
   "metadata": {
    "id": "c4b0d02d-08c2-4a40-ae8a-9634a1274b56",
    "outputId": "9286b060-3f45-4f6f-a409-55378374bac2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/wandb/run-20250701_195704-uyum6lk5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/saghar-adler-personal/huggingface/runs/uyum6lk5' target=\"_blank\">/workspace/gpt2-dpo-imdb</a></strong> to <a href='https://wandb.ai/saghar-adler-personal/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/saghar-adler-personal/huggingface' target=\"_blank\">https://wandb.ai/saghar-adler-personal/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/saghar-adler-personal/huggingface/runs/uyum6lk5' target=\"_blank\">https://wandb.ai/saghar-adler-personal/huggingface/runs/uyum6lk5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3520' max='3520' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3520/3520 45:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.082100</td>\n",
       "      <td>0.078679</td>\n",
       "      <td>-6.619421</td>\n",
       "      <td>-17.387569</td>\n",
       "      <td>0.973400</td>\n",
       "      <td>10.768147</td>\n",
       "      <td>-315.803711</td>\n",
       "      <td>-428.713837</td>\n",
       "      <td>-30.952179</td>\n",
       "      <td>-48.807888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.070190</td>\n",
       "      <td>-8.064950</td>\n",
       "      <td>-21.061266</td>\n",
       "      <td>0.978200</td>\n",
       "      <td>12.996313</td>\n",
       "      <td>-330.259064</td>\n",
       "      <td>-465.450806</td>\n",
       "      <td>-45.057880</td>\n",
       "      <td>-70.751205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.066828</td>\n",
       "      <td>-8.559361</td>\n",
       "      <td>-23.894630</td>\n",
       "      <td>0.981000</td>\n",
       "      <td>15.335272</td>\n",
       "      <td>-335.203125</td>\n",
       "      <td>-493.784454</td>\n",
       "      <td>-51.758068</td>\n",
       "      <td>-76.813622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.068424</td>\n",
       "      <td>-9.440296</td>\n",
       "      <td>-26.522356</td>\n",
       "      <td>0.981600</td>\n",
       "      <td>17.082062</td>\n",
       "      <td>-344.012512</td>\n",
       "      <td>-520.061829</td>\n",
       "      <td>-50.273396</td>\n",
       "      <td>-78.096497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>-9.727662</td>\n",
       "      <td>-27.520519</td>\n",
       "      <td>0.981800</td>\n",
       "      <td>17.792860</td>\n",
       "      <td>-346.886139</td>\n",
       "      <td>-530.043274</td>\n",
       "      <td>-49.534012</td>\n",
       "      <td>-78.051064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n",
      "There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3520, training_loss=0.0319982063901989, metrics={'train_runtime': 2756.3353, 'train_samples_per_second': 81.63, 'train_steps_per_second': 1.277, 'total_flos': 0.0, 'train_loss': 0.0319982063901989, 'epoch': 5.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start DPO fine-tuning\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gfkbCSveSzB2",
   "metadata": {
    "id": "gfkbCSveSzB2"
   },
   "source": [
    "### Inference and Output Comparison Across Checkpoints\n",
    "\n",
    "After training with Direct Preference Optimization (DPO), we evaluate the model's progress by generating completions from the base GPT-2 model and from each checkpoint saved at the end of every epoch. We use the following prompt for all generations:\n",
    "\n",
    "```text\n",
    "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Inference Setup\n",
    "\n",
    "* We generate one completion per prompt for:\n",
    "\n",
    "  * The base model (before fine-tuning)\n",
    "  * Checkpoints at steps: `704`, `1408`, `2112`, `2816`, and `3520` (end of epochs 1 through 5)\n",
    "* Sampling configuration: `top_k=50`, `top_p=0.95`, `temperature=0.9`, `max_new_tokens=100`\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Comparison\n",
    "\n",
    "**Base Model Output**\n",
    "The base GPT-2 model’s output is generic and lacks sentiment alignment. It is off-topic and incoherent toward the end.\n",
    "\n",
    "> *\"...The writing was not very good, but at least they said it had a good ending... There was no voice acting, but they did manage to make a strong voice, which...\"*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 1**\n",
    "\n",
    "The generation shows improved positivity and thematic structure. It reflects action and atmosphere well but becomes somewhat verbose.\n",
    "\n",
    "> *\"...The first few scenes were the perfect light novels... The pace was fast. The action was very good... The tone was very good, and the action was great...\"*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 2**\n",
    "\n",
    "This output suffers from severe repetition and lack of coherence.\n",
    "\n",
    "> *\"Okay, okay, okay...\" (repeated over 30 times)*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 3**\n",
    "\n",
    "The sentiment is positive and aligned, but output is highly redundant.\n",
    "\n",
    "> *\"Overall, this movie was good...\" (repeated almost identically over multiple lines)*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 4**\n",
    "\n",
    "Notable improvement. Shows structured phrasing and more variety.\n",
    "\n",
    "> *\"...a good movie with good chemistry... The story is great. And the action is great...\"*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 5**\n",
    "\n",
    "Tone is positive, but repetition persists.\n",
    "\n",
    "> *\"...it's a great movie... But it's a great movie... And it's good...\"*\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "* The base model fails to generate sentiment-aligned completions.\n",
    "* Epoch 1 begins to align with positive tone and structure.\n",
    "* Epochs 2–3 struggle with redundancy despite improved sentiment.\n",
    "* Epoch 4 shows strong coherence and structured review-style writing.\n",
    "* Epoch 5 maintains tone but overuses similar phrasing.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fddb1b-6359-4b8c-8b62-126fab664c2f",
   "metadata": {
    "id": "83fddb1b-6359-4b8c-8b62-126fab664c2f",
    "outputId": "6999f417-3971-4422-ed66-8f9ef43ec0d1"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7bc7386df7a46cabb6b35ab02b8999d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd1ed7e8d6c483d8db9ae071209d741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a22224eb64ec497fb267557699a78003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0000ff5c51b9436389fa75c5bb62e83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ccca2ea8b1470586b3374896b3e361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== BASE MODEL ====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34102da162e42bc915bbe695fe862b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "330b16ebddfd4f01b78ee34b406053fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Base model output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story... I don't want to judge. The writing was not very good, but at least they said it had a good ending and it had some good action sequences. The characters were very similar to other people I have seen or seen. The script, though, was mostly good. The story was very good. It is good if you want to compare this to other popular anime because it really can't get any better. There was no voice acting, but they did manage to make a strong voice, which\n",
      "\n",
      "==== checkpoint-704 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story... I enjoyed the performance with great intensity. \"The first few scenes were the perfect light novels to show how this world works, but I really enjoyed the performance. The pace was fast. The action was very good, and the action was fast. This is the first time that I watched a fantasy film in my life, and it's the first time that I watched a horror film. The tone was very good, and the action was great. The atmosphere was great. There were many scenes that were\n",
      "\n",
      "==== checkpoint-1408 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story... But I'd like to give you an honest review of it. A good movie. It's good. \"Okay, okay, okay, okay, okay, okay. Okay, OK. Okay, OK. Okay, okay, okay. Okay, OK. Okay. Okay. Okay. Okay. Okay, OK. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay. Okay.\n",
      "\n",
      "==== checkpoint-2112 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story... but that was good. The plot was good and the humor was good. Overall, this movie is a solid movie. This movie was a good movie, but overall, this movie was pretty good. Overall, this movie is a nice movie, and overall, this movie was good. Overall, this movie was good. Overall, this movie was good. Overall, this movie was good. Overall, this movie was good. Overall, this movie was good. Overall, this movie was good. Overall\n",
      "\n",
      "==== checkpoint-2816 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story... But then it clicked immediately, and it was amazing. It's a good movie that has a good plot, but the action is good, and the action is great as well. It's a good movie with some great action, and it's a good movie with good chemistry. It's a good movie, and the chemistry is great. The story is great. And the action is great. It's a good movie with good chemistry. It's a good movie with a good action, and a\n",
      "\n",
      "==== checkpoint-3520 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...but it was good! But it was a great movie, and it's a great movie, and it's a great movie. But it's a great movie. But it's a great movie. But it's good! But it's a great movie. But it's a great movie. But it's a great movie. And it's great. But it's a great movie. But it's a great movie. And it's good. But it's a great movie. And it's\n"
     ]
    }
   ],
   "source": [
    "# === Settings ===\n",
    "base_model_name = \"gpt2\"\n",
    "checkpoint_dir = \"/workspace/gpt2-dpo-imdb\"\n",
    "checkpoint_names = [\n",
    "    \"checkpoint-704\",\n",
    "    \"checkpoint-1408\",\n",
    "    \"checkpoint-2112\",\n",
    "    \"checkpoint-2816\",\n",
    "    \"checkpoint-3520\"\n",
    "]\n",
    "prompts = [\n",
    "    \"Generate a positive movie review based on this input: The acting was mediocre, but the story...\"\n",
    "]\n",
    "output_file = \"generations.txt\"\n",
    "max_new_tokens = 100\n",
    "\n",
    "# === Load Tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# === Generation Function ===\n",
    "def generate_text(model, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.9,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# === Output Helper ===\n",
    "def write_and_print(f, text):\n",
    "    print(text)\n",
    "    f.write(text + \"\\n\")\n",
    "\n",
    "# === Run Generation for Base Model and Checkpoints ===\n",
    "with open(output_file, \"w\") as f:\n",
    "    # Base model\n",
    "    write_and_print(f, \"==== BASE MODEL ====\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(base_model_name).eval().to(\n",
    "        \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    for prompt in prompts:\n",
    "        write_and_print(f, f\"\\nPrompt:\\n{prompt}\")\n",
    "        output = generate_text(base_model, prompt)\n",
    "        write_and_print(f, f\"Base model output:\\n{output}\")\n",
    "\n",
    "    # Fine-tuned checkpoints\n",
    "    for ckpt_name in checkpoint_names:\n",
    "        ckpt_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "        write_and_print(f, f\"\\n==== {ckpt_name} ====\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(ckpt_path).eval().to(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        for prompt in prompts:\n",
    "            write_and_print(f, f\"\\nPrompt:\\n{prompt}\")\n",
    "            output = generate_text(model, prompt)\n",
    "            write_and_print(f, f\"Fine-tuned output:\\n{output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QX_KNofPV1Jr",
   "metadata": {
    "id": "QX_KNofPV1Jr"
   },
   "source": [
    "### Updated Generations with Repetition Penalty\n",
    "\n",
    "In this version, we updated the `generate_text` function to include the `repetition_penalty` parameter. This adjustment helps reduce redundancy  in the model's output by discouraging the reuse of the same tokens repeatedly during decoding. We re-generated completions from the base model and each fine-tuned checkpoint using the previous prompt. Below are the updated outputs after applying the repetition penalty:\n",
    "\n",
    "---\n",
    "\n",
    "#### Output Comparison (With Repetition Penalty)\n",
    "\n",
    "**Base Model Output**\n",
    "\n",
    "The base model remains incoherent and off-topic with no clear positive sentiment or structure.\n",
    "\n",
    "> *\"...there is no redeeming effect in having him as his 'guy'... maybe pick up A2DIII and give some thought to where they fit...\"*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 1**\n",
    "\n",
    "More positive tone and structure appear, with some overgeneralization. The review introduces award references and viewing recommendations.\n",
    "\n",
    "> *\"...excellent film... great voice acting... highly recommend watching him... just as award-winning director for his first feature...\"*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 2**\n",
    "\n",
    "Improved sentence coherence and natural flow. Characters are described in a more human and likable way.\n",
    "\n",
    "> *\"...an enjoyable read... each character individually enough... great stuff... amazing books by Christopher Lee...\"*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 3**\n",
    "\n",
    "Review becomes concise, relevant, and sentiment-aligned. It includes specific narrative details and a clear recommendation.\n",
    "\n",
    "> *\"...very entertaining... highly recommend... a great action flick about a young boy named Jack...\"*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 4**\n",
    "\n",
    "Wide genre coverage and strong recommendation tone. More diverse sentence structure and review realism.\n",
    "\n",
    "> *\"...good action movies that have great comedy themes... plenty different types within each genre... very special feature...\"*\n",
    "\n",
    "---\n",
    "\n",
    "**Epoch 5**\n",
    "\n",
    "Shows a polished and mature review style. References acting, character interaction, and notable cast members.\n",
    "\n",
    "> *\"...good and interesting... really enjoyed watching... terrific performance from Chris Rock...\"*\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "\n",
    "* Adding `repetition_penalty=1.2` reduced redundancy and improved diversity in outputs.\n",
    "* Base model remained generic and sentiment-neutral.\n",
    "* From Epoch 1, outputs showed increasing alignment with prompt intent.\n",
    "* Epochs 2–3 delivered more human-like structure and focus.\n",
    "* Epochs 4–5 produced well-rounded reviews with genre and cast references.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e3a280e-370b-4cd1-a23c-5aa9e3ef5106",
   "metadata": {
    "id": "1e3a280e-370b-4cd1-a23c-5aa9e3ef5106",
    "outputId": "75c6e609-3ae1-4b74-ad54-442e6db25331"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== BASE MODEL ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Base model output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story... well enough that it's not considered to be good. Even without trying out all of these different ways, there is no redeeming effect in having him as his \"guy\" (as he'd usually call himself).\n",
      "That being said if you are looking for something better than your previous two trailers , or get yourself into another one with other people working at Warner Bros., then maybe pick up A2DIII and give some thought to where they fit between them while making sure everyone knows exactly what their\n",
      "\n",
      "==== checkpoint-704 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned model output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story... But overall it is an excellent film. It's one of my favorite movies that has great voice acting in its own right and features tons at once with terrific actors. I highly recommend watching him! Overall rating Rating Of This Review - 5/10\n",
      "\n",
      "\n",
      "The best movie of 2015 by far from any other reviews yet, he can be considered just as award-winning director for his first feature of 2016 while also being among many excellent filmmakers and directors to watch. If you have a strong passion or desire\n",
      "\n",
      "==== checkpoint-1408 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned model output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story... It's pretty good. Overall it is an enjoyable read and I recommend getting to know each character individually enough for them at their own pace--they're all likable in their respective roles; they get along with each other easily as you play. This book provides a nice little introduction into how much of something that makes up his or her personality. Great stuff! There are many more than 100 chapters worth including some terrific stories such things like one of those amazing books by Christopher Lee called 'The Secret History\n",
      "\n",
      "==== checkpoint-2112 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned model output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story... it's simple. It is very entertaining and well received by people who have never watched anything of mine before and I highly recommend this film to them. Overall overall rating : 7/10 \"This is a great action flick about a young boy named Jack that travels around town with an awesome lady friend called Mrs. Lee (played by her husband) for his first time in awhile. But things can change fast so she gives you what feels right from the beginning to the end and makes sure you succeed as\n",
      "\n",
      "==== checkpoint-2816 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned model output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...but it's okay! It works out quite well. This is what I recommend to all of my friends and family who want some good action movies that have great comedy themes. But there are so many excellent films which do a wonderful job with a strong narrative element. There are plenty different types within each genre; Action, Adventure or Sci-Fi. And yet, you will immediately recognize them as one very special feature that I'm proud to introduce (and welcome) by introducing you once again into their\n",
      "\n",
      "==== checkpoint-3520 ====\n",
      "\n",
      "Prompt:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...\n",
      "Fine-tuned model output:\n",
      "Generate a positive movie review based on this input: The acting was mediocre, but the story...but it's good and interesting. I really enjoyed watching that scene and watching what he did with his character and how they interacted. Overall though much of my life is created by actors in their early 20s these days (i'm still around) so this scene had some very strong cast members as well. It was great to watch and enjoy! \"The Last Stand\" Part II: The Movie\" Part III : A terrific performance from Chris Rock which brought out the best parts in a rock star like\n"
     ]
    }
   ],
   "source": [
    "# === Settings ===\n",
    "base_model_name = \"gpt2\"\n",
    "checkpoint_dir = \"/workspace/gpt2-dpo-imdb\"\n",
    "checkpoint_names = [\n",
    "    \"checkpoint-704\",\n",
    "    \"checkpoint-1408\",\n",
    "    \"checkpoint-2112\",\n",
    "    \"checkpoint-2816\",\n",
    "    \"checkpoint-3520\"\n",
    "]\n",
    "prompts = [\n",
    "    \"Generate a positive movie review based on this input: The acting was mediocre, but the story...\"\n",
    "]\n",
    "output_file = \"generations_v2.txt\"\n",
    "max_new_tokens = 100\n",
    "\n",
    "# === Load Tokenizer ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# === Generation Function ===\n",
    "def generate_text(model, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=True,\n",
    "            top_k=50,\n",
    "            top_p=0.95,\n",
    "            temperature=0.9,\n",
    "            repetition_penalty=1.2,    # Add repetition_penalty to discourage repetitive output\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "# === Generate Outputs for Base Model and Fine-Tuned Checkpoints ===\n",
    "with open(output_file, \"w\") as f:\n",
    "    # Base model output\n",
    "    write_and_print(f, \"==== BASE MODEL ====\")\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(base_model_name).eval().to(\n",
    "        \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    )\n",
    "    for prompt in prompts:\n",
    "        write_and_print(f, f\"\\nPrompt:\\n{prompt}\")\n",
    "        output = generate_text(base_model, prompt)\n",
    "        write_and_print(f, f\"Base model output:\\n{output}\")\n",
    "\n",
    "    # Outputs from each fine-tuned checkpoint\n",
    "    for ckpt_name in checkpoint_names:\n",
    "        ckpt_path = os.path.join(checkpoint_dir, ckpt_name)\n",
    "        write_and_print(f, f\"\\n==== {ckpt_name} ====\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(ckpt_path).eval().to(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "        for prompt in prompts:\n",
    "            write_and_print(f, f\"\\nPrompt:\\n{prompt}\")\n",
    "            output = generate_text(model, prompt)\n",
    "            write_and_print(f, f\"Fine-tuned model output:\\n{output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b11b68a-fc71-4d4c-9303-4d52114a2129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
